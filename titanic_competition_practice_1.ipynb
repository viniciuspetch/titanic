{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "titanic_train = pd.read_csv('train.csv')\n",
    "titanic_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# We have a train dataset, which we'll use to train and validate our models, and the test dataset, which we'll submit the values\n",
    "# Printing the columns and number of instances on the train and test datasets\n",
    "print(titanic_train.columns)\n",
    "print(titanic_test.columns)\n",
    "print(titanic_train.shape)\n",
    "print(titanic_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of elements in each attribute\n",
    "print(titanic_train.count())\n",
    "# Checking the type of each attribute\n",
    "print(titanic_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using describe to analyse the numerial attributes\n",
    "titanic_train.describe()\n",
    "# There's missing values in Age and Cabin;\n",
    "# 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked' are strings, we need to check if they're categorial or nominal;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic_train.Name.head())\n",
    "# Name is identifier - discard\n",
    "print(titanic_train.Sex.head())\n",
    "# Sex is categorical, but binary - change to 0/1\n",
    "print(titanic_train.Ticket.head())\n",
    "# Ticket is a string, description - discard\n",
    "print(titanic_train.Cabin.head())\n",
    "# Cabin is a identifier, might be useful - discard, however\n",
    "print(titanic_train.Embarked.head())\n",
    "# Embarked is nominal - one-hot needed, discard for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copy\n",
    "ttn = titanic_train\n",
    "# Drop all attributes we don't want\n",
    "ttn = ttn.drop('PassengerId', axis=1)\n",
    "ttn = ttn.drop('Name', axis=1)\n",
    "ttn = ttn.drop('Ticket', axis=1)\n",
    "ttn = ttn.drop('Cabin', axis=1)\n",
    "ttn = ttn.drop('Embarked', axis=1)\n",
    "# Change sex to a integer value\n",
    "ttn['Sex'] = ttn['Sex'].replace({'male': 0, 'female': 1})\n",
    "ttn_na = ttn.copy()\n",
    "# Fill in age with the mean\n",
    "ttn['Age'] = ttn['Age'].fillna(ttn['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation\n",
    "for i in ttn.columns:\n",
    "    print(ttn.corr()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the dataset\n",
    "temp = ttn.copy()\n",
    "for feature_name in ttn.columns:\n",
    "    maxv = ttn[feature_name].max()\n",
    "    minv = ttn[feature_name].min()\n",
    "    temp[feature_name] = (ttn[feature_name] - minv) / (maxv - minv)\n",
    "ttn_norm = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split train (80%) and test (20%)\n",
    "def split(df):\n",
    "    X_train, X_test = train_test_split(df, test_size = 0.2)\n",
    "    Y_train = X_train['Survived']\n",
    "    X_train = X_train.drop('Survived', axis=1)\n",
    "    Y_test = X_test['Survived']\n",
    "    X_test = X_test.drop('Survived', axis=1)\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "# Split features and class for the cross validation\n",
    "def crossval_split(df):\n",
    "    Y = df['Survived']\n",
    "    X = df.drop('Survived', axis=1)\n",
    "    return X, Y\n",
    "\n",
    "#K-NN function\n",
    "def knn_run(db, n=5, weights='uniform', algorithm='auto', p=2):    \n",
    "    X, Y = crossval_split(db)\n",
    "    clf = KNeighborsClassifier(n_neighbors=n, weights=weights, algorithm=algorithm, p=p)\n",
    "    scores = cross_val_score(clf, X, Y, cv=10)\n",
    "    return scores\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "def bayes_run(db):\n",
    "    X, Y = crossval_split(db)\n",
    "    clf = GaussianNB()\n",
    "    scores = cross_val_score(clf, X, Y, cv=10)\n",
    "    return scores\n",
    "\n",
    "# Decision Tree\n",
    "def dectree_run(db, depth=None):\n",
    "    X, Y = crossval_split(db)\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=depth)    \n",
    "    scores = cross_val_score(clf, X, Y, cv=10)\n",
    "    return scores\n",
    "\n",
    "# SVM\n",
    "from sklearn import svm\n",
    "def svm_run(db, kernel='rbf', gamma='scale'):\n",
    "    X, Y = crossval_split(db)\n",
    "    clf = svm.SVC(gamma=gamma, kernel=kernel)\n",
    "    scores = cross_val_score(clf, X, Y, cv=10)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_score_list_orig = []\n",
    "knn_score_list = []\n",
    "for i in range(1,11):\n",
    "    knn_score_list_orig.append(knn_run(ttn, n=i))\n",
    "for i in range(1,11):\n",
    "    knn_score_list.append(knn_run(ttn_norm, n=i))\n",
    "    \n",
    "# Compare normal database with a normalized one\n",
    "fig1, ax1 = plt.subplots(ncols=2, sharey='all')\n",
    "ax1[0].boxplot(knn_score_list_orig)\n",
    "ax1[1].boxplot(knn_score_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare knn/algorithms\n",
    "knn_score_list_ball = []\n",
    "knn_score_list_kd = []\n",
    "knn_score_list_brute = []\n",
    "for i in range(1,11):\n",
    "    knn_score_list_ball.append(knn_run(ttn_norm, n=i, algorithm='ball_tree'))\n",
    "for i in range(1,11):\n",
    "    knn_score_list_kd.append(knn_run(ttn_norm, n=i, algorithm='kd_tree'))\n",
    "for i in range(1,11):\n",
    "    knn_score_list_brute.append(knn_run(ttn_norm, n=i, algorithm='brute'))\n",
    "\n",
    "fig1, ax1 = plt.subplots(ncols=3, sharey='all')\n",
    "ax1[0].boxplot(knn_score_list_ball)\n",
    "ax1[1].boxplot(knn_score_list_kd)\n",
    "ax1[2].boxplot(knn_score_list_brute)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare knn/weights\n",
    "knn_score_list_uniform = []\n",
    "knn_score_list_distance = []\n",
    "for i in range(1,11):\n",
    "    knn_score_list_uniform.append(knn_run(ttn_norm, n=i, weights='uniform'))\n",
    "for i in range(1,11):\n",
    "    knn_score_list_distance.append(knn_run(ttn_norm, n=i, weights='distance'))\n",
    "\n",
    "fig1, ax1 = plt.subplots(ncols=2, sharey='all')\n",
    "ax1[0].boxplot(knn_score_list_uniform)\n",
    "ax1[1].boxplot(knn_score_list_distance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.boxplot([bayes_run(ttn), bayes_run(ttn_norm)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Decision Tree to both datasets\n",
    "dectree_score_orig = dectree_run(ttn) \n",
    "dectree_score = dectree_run(ttn_norm)\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.boxplot([dectree_score_orig, dectree_score])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multiple depths\n",
    "dectree_score_depth = []\n",
    "for i in range(1,30):\n",
    "    dectree_score_depth.append(dectree_run(ttn, depth=i))\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.boxplot(dectree_score_depth)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "svm_score_orig = []\n",
    "svm_score = []\n",
    "for i in ['rbf', 'poly', 'sigmoid']:\n",
    "    svm_score_orig.append(svm_run(ttn, kernel=i))\n",
    "    svm_score.append(svm_run(ttn_norm, kernel=i))\n",
    "\n",
    "fig1, ax1 = plt.subplots(ncols=2, sharey='all')\n",
    "ax1[0].boxplot(svm_score_orig)\n",
    "ax1[1].boxplot(svm_score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridsearch test\n",
    "X_train, Y_train, X_test, Y_test = split(ttn_norm)\n",
    "param = {'kernel':['rbf', 'linear', ]}\n",
    "svc = svm.SVC(gamma='scale')\n",
    "clf = GridSearchCV(svc, param, cv=5)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "print(clf.cv_results_['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare everybody\n",
    "fig1, ax1 = plt.subplots(ncols=4, sharey='all')\n",
    "ax1[0].boxplot(knn_score_list_uniform)\n",
    "ax1[1].boxplot([bayes_run(ttn), bayes_run(ttn_norm)])\n",
    "ax1[2].boxplot(dectree_score_depth[0:10])\n",
    "ax1[3].boxplot(svm_score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copy\n",
    "test = titanic_test\n",
    "# Drop all attributes we don't want\n",
    "test = test.drop('PassengerId', axis=1)\n",
    "test = test.drop('Name', axis=1)\n",
    "test = test.drop('Ticket', axis=1)\n",
    "test = test.drop('Cabin', axis=1)\n",
    "test = test.drop('Embarked', axis=1)\n",
    "# Change sex to a integer value\n",
    "test['Sex'] = test['Sex'].replace({'male': 0, 'female': 1})\n",
    "# Fill in age with the mean\n",
    "test = test.fillna(test.median())\n",
    "\n",
    "# Normalize the dataset\n",
    "temp = test.copy()\n",
    "for feature_name in test.columns:\n",
    "    maxv = test[feature_name].max()\n",
    "    minv = test[feature_name].min()\n",
    "    temp[feature_name] = (test[feature_name] - minv) / (maxv - minv)\n",
    "test = temp\n",
    "\n",
    "X, Y = crossval_split(ttn_norm)\n",
    "clf = KNeighborsClassifier(n_neighbors=4)\n",
    "clf.fit(X, Y)\n",
    "prediction = clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results\n",
    "data = {'PassengerId': titanic_test['PassengerId'], 'Survived': prediction.astype(int)}\n",
    "pd.DataFrame(data).to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
